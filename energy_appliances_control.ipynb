{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import tensorflow.keras.utils as utils\n",
    "import pydot\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"./Datasets/energydata_complete.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>...</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:00:00</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.20</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.53</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>733.500000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>13.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:10:00</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.20</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.992500</td>\n",
       "      <td>...</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>45.56</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>733.600000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>18.606195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:20:00</th>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.20</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>45.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.50</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>733.700000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>28.642668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:30:00</th>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.20</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.723333</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>733.800000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>45.410389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:40:00</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.20</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>733.900000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>10.084097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:50:00</th>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.026667</td>\n",
       "      <td>19.20</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.730000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.29</td>\n",
       "      <td>6.016667</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>43.833333</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>44.919484</td>\n",
       "      <td>44.919484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 18:00:00</th>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>45.766667</td>\n",
       "      <td>19.20</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.900000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.790000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.29</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>734.100000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>47.233763</td>\n",
       "      <td>47.233763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 18:10:00</th>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>19.856667</td>\n",
       "      <td>45.560000</td>\n",
       "      <td>19.20</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>19.73</td>\n",
       "      <td>44.900000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.863333</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.29</td>\n",
       "      <td>5.916667</td>\n",
       "      <td>734.166667</td>\n",
       "      <td>91.833333</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.683333</td>\n",
       "      <td>33.039890</td>\n",
       "      <td>33.039890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 18:20:00</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>45.597500</td>\n",
       "      <td>19.20</td>\n",
       "      <td>44.433333</td>\n",
       "      <td>19.73</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.790000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.29</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>734.233333</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>31.455702</td>\n",
       "      <td>31.455702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 18:30:00</th>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>19.856667</td>\n",
       "      <td>46.090000</td>\n",
       "      <td>19.23</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.863333</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>46.096667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.29</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>734.300000</td>\n",
       "      <td>91.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>3.089314</td>\n",
       "      <td>3.089314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Appliances  lights         T1       RH_1     T2  \\\n",
       "date                                                                   \n",
       "2016-01-11 17:00:00          60      30  19.890000  47.596667  19.20   \n",
       "2016-01-11 17:10:00          60      30  19.890000  46.693333  19.20   \n",
       "2016-01-11 17:20:00          50      30  19.890000  46.300000  19.20   \n",
       "2016-01-11 17:30:00          50      40  19.890000  46.066667  19.20   \n",
       "2016-01-11 17:40:00          60      40  19.890000  46.333333  19.20   \n",
       "2016-01-11 17:50:00          50      40  19.890000  46.026667  19.20   \n",
       "2016-01-11 18:00:00          60      50  19.890000  45.766667  19.20   \n",
       "2016-01-11 18:10:00          60      50  19.856667  45.560000  19.20   \n",
       "2016-01-11 18:20:00          60      40  19.790000  45.597500  19.20   \n",
       "2016-01-11 18:30:00          70      40  19.856667  46.090000  19.23   \n",
       "\n",
       "                          RH_2     T3       RH_3         T4       RH_4  ...  \\\n",
       "date                                                                    ...   \n",
       "2016-01-11 17:00:00  44.790000  19.79  44.730000  19.000000  45.566667  ...   \n",
       "2016-01-11 17:10:00  44.722500  19.79  44.790000  19.000000  45.992500  ...   \n",
       "2016-01-11 17:20:00  44.626667  19.79  44.933333  18.926667  45.890000  ...   \n",
       "2016-01-11 17:30:00  44.590000  19.79  45.000000  18.890000  45.723333  ...   \n",
       "2016-01-11 17:40:00  44.530000  19.79  45.000000  18.890000  45.530000  ...   \n",
       "2016-01-11 17:50:00  44.500000  19.79  44.933333  18.890000  45.730000  ...   \n",
       "2016-01-11 18:00:00  44.500000  19.79  44.900000  18.890000  45.790000  ...   \n",
       "2016-01-11 18:10:00  44.500000  19.73  44.900000  18.890000  45.863333  ...   \n",
       "2016-01-11 18:20:00  44.433333  19.73  44.790000  18.890000  45.790000  ...   \n",
       "2016-01-11 18:30:00  44.400000  19.79  44.863333  18.890000  46.096667  ...   \n",
       "\n",
       "                            T9   RH_9     T_out  Press_mm_hg     RH_out  \\\n",
       "date                                                                      \n",
       "2016-01-11 17:00:00  17.033333  45.53  6.600000   733.500000  92.000000   \n",
       "2016-01-11 17:10:00  17.066667  45.56  6.483333   733.600000  92.000000   \n",
       "2016-01-11 17:20:00  17.000000  45.50  6.366667   733.700000  92.000000   \n",
       "2016-01-11 17:30:00  17.000000  45.40  6.250000   733.800000  92.000000   \n",
       "2016-01-11 17:40:00  17.000000  45.40  6.133333   733.900000  92.000000   \n",
       "2016-01-11 17:50:00  17.000000  45.29  6.016667   734.000000  92.000000   \n",
       "2016-01-11 18:00:00  17.000000  45.29  5.900000   734.100000  92.000000   \n",
       "2016-01-11 18:10:00  17.000000  45.29  5.916667   734.166667  91.833333   \n",
       "2016-01-11 18:20:00  17.000000  45.29  5.933333   734.233333  91.666667   \n",
       "2016-01-11 18:30:00  17.000000  45.29  5.950000   734.300000  91.500000   \n",
       "\n",
       "                     Windspeed  Visibility  Tdewpoint        rv1        rv2  \n",
       "date                                                                         \n",
       "2016-01-11 17:00:00   7.000000   63.000000   5.300000  13.275433  13.275433  \n",
       "2016-01-11 17:10:00   6.666667   59.166667   5.200000  18.606195  18.606195  \n",
       "2016-01-11 17:20:00   6.333333   55.333333   5.100000  28.642668  28.642668  \n",
       "2016-01-11 17:30:00   6.000000   51.500000   5.000000  45.410389  45.410389  \n",
       "2016-01-11 17:40:00   5.666667   47.666667   4.900000  10.084097  10.084097  \n",
       "2016-01-11 17:50:00   5.333333   43.833333   4.800000  44.919484  44.919484  \n",
       "2016-01-11 18:00:00   5.000000   40.000000   4.700000  47.233763  47.233763  \n",
       "2016-01-11 18:10:00   5.166667   40.000000   4.683333  33.039890  33.039890  \n",
       "2016-01-11 18:20:00   5.333333   40.000000   4.666667  31.455702  31.455702  \n",
       "2016-01-11 18:30:00   5.500000   40.000000   4.650000   3.089314   3.089314  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_dir, index_col=0)\n",
    "df = df.fillna(df.mean())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns is: 28 and number of rows is: 19735\n"
     ]
    }
   ],
   "source": [
    "col_num = len(df.columns)\n",
    "row_num = len(df.index)\n",
    "print(\"Number of columns is: {} and number of rows is: {}\".format(col_num, row_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = df.iloc[:int(0.8*row_num), 1:(col_num-2)]\n",
    "trainy = df.iloc[:int(0.8*row_num), 0]\n",
    "\n",
    "testx = df.iloc[int(0.8*row_num):, 1:(col_num-2)]\n",
    "testy = df.iloc[int(0.8*row_num):, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "trainx_scaled = pd.DataFrame(scaler.fit_transform(trainx), columns = trainx.columns, index = trainx.index)\n",
    "textx_scaled = pd.DataFrame(scaler.transform(testx), columns = testx.columns, index = testx.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_A_train_x_op = trainx_scaled.iloc[:,[0,19,20,21,22,23,24]] \n",
    "group_B_train_x_op = trainx_scaled.iloc[:,[1,2,3,4,5,6,7,8,9,10]]\n",
    "group_C_train_x_op = trainx_scaled.iloc[:,[11,12,13,14,15,16,17,18]]\n",
    "\n",
    "group_A_test_x_op = textx_scaled.iloc[:,[0,19,20,21,22,23,24]]\n",
    "group_B_test_x_op = textx_scaled.iloc[:,[1,2,3,4,5,6,7,8,9,10]]\n",
    "group_C_test_x_op = textx_scaled.iloc[:,[11,12,13,14,15,16,17,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_inp_a = len(group_A_train_x_op.columns)\n",
    "size_inp_b = len(group_B_train_x_op.columns)\n",
    "size_inp_c = len(group_C_train_x_op.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MICS_model(inp_sizeA, inp_sizeB, inp_sizeC, use_encoders, drop_out, hidden_num = 4, hidden_size=32):\n",
    "    inputs_A = keras.layers.Input(shape=(inp_sizeA), name=\"input_A\")\n",
    "    inputs_B = keras.layers.Input(shape=(inp_sizeB), name=\"input_B\")\n",
    "    inputs_C = keras.layers.Input(shape=(inp_sizeC), name=\"input_C\")\n",
    "    \n",
    "    #If encoders are not to be used, inputs will be directly given to global model\n",
    "    \n",
    "    if use_encoders == True:\n",
    "        encoder_A = get_encoder_model(inp_sizeA)\n",
    "        encoder_B = get_encoder_model(inp_sizeB)\n",
    "        encoder_C = get_encoder_model(inp_sizeC)\n",
    "    \n",
    "        global_inp_A = encoder_A(inputs_A)\n",
    "        global_inp_B = encoder_B(inputs_B)\n",
    "        global_inp_C = encoder_C(inputs_C)\n",
    "\n",
    "        global_inp = keras.layers.concatenate([global_inp_A, global_inp_B, global_inp_C])\n",
    "    else:\n",
    "        global_inp = keras.layers.concatenate([inputs_A, inputs_A, inputs_A])\n",
    "        \n",
    "    h = keras.layers.Dense(hidden_size, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=1e-4, l2=1e-3))(global_inp)\n",
    "    h = keras.layers.Dropout(drop_out)(h)\n",
    "    for hidden in range(hidden_num):\n",
    "        h = keras.layers.Dense(hidden_size, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=1e-4, l2=1e-3))(h)\n",
    "        h = keras.layers.Dropout(drop_out)(h) \n",
    "\n",
    "    outputs = keras.layers.Dense(1, activation=\"relu\")(h)    \n",
    "    return keras.Model(inputs=[inputs_A, inputs_B, inputs_C], outputs = outputs)\n",
    "\n",
    "def get_encoder_model(inp_size):\n",
    "    inputs = keras.layers.Input(shape=(inp_size))\n",
    "    h1 = keras.layers.Dense(10, activation=\"relu\")(inputs)\n",
    "    outputs = keras.layers.Dense(inp_size, activation=\"relu\")(h1)\n",
    "    return keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 11142.6865 - val_loss: 8829.3750\n",
      "Epoch 2/300\n",
      "1579/1579 [==============================] - 2s 1ms/step - loss: 10104.6074 - val_loss: 9068.9219\n",
      "Epoch 3/300\n",
      "1579/1579 [==============================] - 2s 1ms/step - loss: 9834.8398 - val_loss: 8750.1807\n",
      "Epoch 4/300\n",
      "1579/1579 [==============================] - 2s 1ms/step - loss: 9892.5654 - val_loss: 8425.8018\n",
      "Epoch 5/300\n",
      "1579/1579 [==============================] - 2s 1ms/step - loss: 9961.8018 - val_loss: 9059.3838\n",
      "Epoch 6/300\n",
      "1579/1579 [==============================] - 2s 1ms/step - loss: 10020.3975 - val_loss: 8786.1094\n",
      "Epoch 7/300\n",
      "1579/1579 [==============================] - 2s 1ms/step - loss: 10031.2373 - val_loss: 8989.5947\n",
      "Epoch 8/300\n",
      "1579/1579 [==============================] - 2s 1ms/step - loss: 10041.4170 - val_loss: 9169.2285\n",
      "Epoch 9/300\n",
      "1579/1579 [==============================] - 2s 1ms/step - loss: 10168.2207 - val_loss: 9362.9590\n",
      "Epoch 10/300\n",
      "1579/1579 [==============================] - 2s 1ms/step - loss: 10620.0449 - val_loss: 9342.4326\n",
      "Epoch 11/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10396.3857 - val_loss: 9347.5166\n",
      "Epoch 12/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10358.1006 - val_loss: 9516.5205\n",
      "Epoch 13/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10415.6289 - val_loss: 9303.3477\n",
      "Epoch 14/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10486.0869 - val_loss: 9696.4258\n",
      "Epoch 15/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10261.6523 - val_loss: 8957.5332\n",
      "Epoch 16/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 9995.8232 - val_loss: 8927.8662\n",
      "Epoch 17/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10284.6094 - val_loss: 9958.7744\n",
      "Epoch 18/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10473.0889 - val_loss: 9639.3633\n",
      "Epoch 19/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10411.9570 - val_loss: 9166.7715\n",
      "Epoch 20/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10097.9883 - val_loss: 9038.2656\n",
      "Epoch 21/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10184.8008 - val_loss: 9328.0361\n",
      "Epoch 22/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10008.1602 - val_loss: 9232.5840\n",
      "Epoch 23/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10198.6748 - val_loss: 9053.6094\n",
      "Epoch 24/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 9899.6396 - val_loss: 8902.0703\n",
      "Epoch 25/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10028.0967 - val_loss: 8902.7666\n",
      "Epoch 26/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10013.0098 - val_loss: 9145.4180\n",
      "Epoch 27/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 9848.0879 - val_loss: 9281.1533\n",
      "Epoch 28/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10063.9219 - val_loss: 9871.6875\n",
      "Epoch 29/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 11193.0811 - val_loss: 9319.1221\n",
      "Epoch 30/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10327.2100 - val_loss: 9515.8271\n",
      "Epoch 31/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10412.1787 - val_loss: 9903.0146\n",
      "Epoch 32/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10641.7168 - val_loss: 9977.9385\n",
      "Epoch 33/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10317.0029 - val_loss: 9750.9756\n",
      "Epoch 34/300\n",
      "1545/1579 [============================>.] - ETA: 0s - loss: 10568.4814\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10533.5410 - val_loss: 9935.9746\n",
      "Epoch 35/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10628.1494 - val_loss: 9834.0889\n",
      "Epoch 36/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10659.0020 - val_loss: 9813.4307\n",
      "Epoch 37/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10460.5186 - val_loss: 9359.2246\n",
      "Epoch 38/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10444.9229 - val_loss: 9624.5781\n",
      "Epoch 39/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 11571.5039 - val_loss: 9625.8770\n",
      "Epoch 40/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10049.1787 - val_loss: 9079.6357\n",
      "Epoch 41/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 9909.0859 - val_loss: 9353.1016\n",
      "Epoch 42/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10149.6689 - val_loss: 9299.7148\n",
      "Epoch 43/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10473.8877 - val_loss: 9678.3535\n",
      "Epoch 44/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10223.3965 - val_loss: 9566.0381\n",
      "Epoch 45/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10180.9590 - val_loss: 9251.1494\n",
      "Epoch 46/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 9968.3535 - val_loss: 8931.3760\n",
      "Epoch 47/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 9940.3174 - val_loss: 9199.8428\n",
      "Epoch 48/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10058.9180 - val_loss: 9410.3135\n",
      "Epoch 49/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10332.4209 - val_loss: 9427.9004\n",
      "Epoch 50/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10030.1143 - val_loss: 9269.8564\n",
      "Epoch 51/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10218.1729 - val_loss: 9348.6221\n",
      "Epoch 52/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 9863.5908 - val_loss: 8913.6162\n",
      "Epoch 53/300\n",
      "1579/1579 [==============================] - 2s 2ms/step - loss: 10013.8936 - val_loss: 9099.4473\n",
      "Epoch 54/300\n",
      "1579/1579 [==============================] - 3s 2ms/step - loss: 10043.3848 - val_loss: 9103.2256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8425.8017578125"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MICS_model = get_MICS_model(size_inp_a, size_inp_b, size_inp_c, use_encoders = True, drop_out = 0.25)\n",
    "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50), \n",
    "        keras.callbacks.ReduceLROnPlateau(\"val_loss\", factor = 0.8, patience=30,\n",
    "                                         verbose = 2, mode = \"auto\", \n",
    "                                          min_lr = 1e-6)]\n",
    "MICS_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=keras.losses.MeanSquaredError())\n",
    "history = MICS_model.fit(x = [group_A_train_x_op.values, group_B_train_x_op.values, group_C_train_x_op.values], y = trainy.values,  \n",
    "                         validation_data = ([group_A_test_x_op.values, group_B_test_x_op.values, group_C_test_x_op.values], testy.values),\n",
    "                         epochs=300, batch_size = 10, callbacks=callback)\n",
    "training_val_loss = history.history[\"val_loss\"]\n",
    "best_row_index = np.argmin(training_val_loss)\n",
    "best_val_loss = training_val_loss[best_row_index]\n",
    "best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
